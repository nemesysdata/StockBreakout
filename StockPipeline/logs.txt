sed: couldn't open temporary file /opt/flink/conf/sedzqNzKL: Read-only file system
sed: couldn't open temporary file /opt/flink/conf/sedqKpNhh: Read-only file system
/docker-entrypoint.sh: line 73: /opt/flink/conf/flink-conf.yaml: Permission denied
/docker-entrypoint.sh: line 89: /opt/flink/conf/flink-conf.yaml.tmp: Read-only file system
Starting kubernetes-application as a console application on host stock-pipeline-agg-aapl-59b85f5975-5bzwz.
2024-12-15 17:31:28,992 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2024-12-15 17:31:29,000 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Preconfiguration: 
2024-12-15 17:31:29,001 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - 


RESOURCE_PARAMS extraction logs:
jvm_params: -Xmx469762048 -Xms469762048 -XX:MaxMetaspaceSize=268435456
dynamic_configs: -D jobmanager.memory.off-heap.size=134217728b -D jobmanager.memory.jvm-overhead.min=201326592b -D jobmanager.memory.jvm-metaspace.size=268435456b -D jobmanager.memory.heap.size=469762048b -D jobmanager.memory.jvm-overhead.max=201326592b
logs: WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.
INFO  [] - Loading configuration property: blob.server.port, 6124
INFO  [] - Loading configuration property: kubernetes.jobmanager.annotations, flinkdeployment.flink.apache.org/generation:2
INFO  [] - Loading configuration property: kubernetes.jobmanager.replicas, 1
INFO  [] - Loading configuration property: execution.submit-failed-job-on-application-error, true
INFO  [] - Loading configuration property: jobmanager.rpc.address, stock-pipeline-agg-aapl.flink
INFO  [] - Loading configuration property: kubernetes.service-account, flink
INFO  [] - Loading configuration property: kubernetes.cluster-id, stock-pipeline-agg-aapl
INFO  [] - Loading configuration property: kubernetes.taskmanager.cpu.amount, 1.0
INFO  [] - Loading configuration property: $internal.application.program-args, -pyclientexec;/usr/local/bin/python3;-py;/opt/flink/usrlib/stock_pipeline.py
INFO  [] - Loading configuration property: parallelism.default, 1
INFO  [] - Loading configuration property: kubernetes.namespace, flink
INFO  [] - Loading configuration property: taskmanager.numberOfTaskSlots, 1
INFO  [] - Loading configuration property: kubernetes.rest-service.exposed.type, ClusterIP
INFO  [] - Loading configuration property: kubernetes.jobmanager.owner.reference, uid:16fa2cf1-7203-40fd-988a-9e15363a43e5,name:stock-pipeline-agg-aapl,controller:false,blockOwnerDeletion:true,apiVersion:flink.apache.org/v1beta1,kind:FlinkDeployment
INFO  [] - Loading configuration property: kubernetes.container.image.ref, nemesysdata/stock-pipeline:latest
INFO  [] - Loading configuration property: $internal.application.main, org.apache.flink.client.python.PythonDriver
INFO  [] - Loading configuration property: taskmanager.memory.process.size, 1 gb
INFO  [] - Loading configuration property: kubernetes.internal.jobmanager.entrypoint.class, org.apache.flink.kubernetes.entrypoint.KubernetesApplicationClusterEntrypoint
INFO  [] - Loading configuration property: pipeline.name, stock-pipeline-agg-aapl
INFO  [] - Loading configuration property: kubernetes.pod-template-file.taskmanager, /tmp/flink_op_generated_podTemplate_5186896621385261630.yaml
INFO  [] - Loading configuration property: web.cancel.enable, false
INFO  [] - Loading configuration property: execution.target, kubernetes-application
INFO  [] - Loading configuration property: jobmanager.memory.process.size, 1 gb
INFO  [] - Loading configuration property: execution.shutdown-on-application-finish, false
INFO  [] - Loading configuration property: taskmanager.rpc.port, 6122
INFO  [] - Loading configuration property: kubernetes.container.image.pull-policy, Always
INFO  [] - Loading configuration property: kubernetes.jobmanager.cpu.amount, 1.0
INFO  [] - Loading configuration property: internal.cluster.execution-mode, NORMAL
INFO  [] - Loading configuration property: $internal.pipeline.job-id, fae872477441fefbceebfb1ff4ad974a
INFO  [] - Loading configuration property: pipeline.jars, local:///opt/flink/opt/flink-python_2.12-1.16.1.jar
INFO  [] - Loading configuration property: execution.checkpointing.externalized-checkpoint-retention, RETAIN_ON_CANCELLATION
INFO  [] - Loading configuration property: $internal.flink.version, v1_17
INFO  [] - Loading configuration property: kubernetes.pod-template-file.jobmanager, /tmp/flink_op_generated_podTemplate_12708019663807171900.yaml
INFO  [] - The derived from fraction jvm overhead memory (102.400mb (107374184 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead
INFO  [] - Final Master Memory configuration:
INFO  [] -   Total Process Memory: 1024.000mb (1073741824 bytes)
INFO  [] -     Total Flink Memory: 576.000mb (603979776 bytes)
INFO  [] -       JVM Heap:         448.000mb (469762048 bytes)
INFO  [] -       Off-heap:         128.000mb (134217728 bytes)
INFO  [] -     JVM Metaspace:      256.000mb (268435456 bytes)
INFO  [] -     JVM Overhead:       192.000mb (201326592 bytes)

2024-12-15 17:31:29,027 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2024-12-15 17:31:29,028 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Starting KubernetesApplicationClusterEntrypoint (Version: 1.18.0, Scala: 2.12, Rev:a5548cc, Date:2023-10-18T22:09:35+02:00)
2024-12-15 17:31:29,028 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  OS current user: flink
2024-12-15 17:31:29,029 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Current Hadoop/Kerberos user: <no hadoop dependency found>
2024-12-15 17:31:29,030 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JVM: OpenJDK 64-Bit Server VM - Eclipse Adoptium - 11/11.0.21+9
2024-12-15 17:31:29,030 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Arch: amd64
2024-12-15 17:31:29,031 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Maximum heap size: 433 MiBytes
2024-12-15 17:31:29,031 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JAVA_HOME: /opt/java/openjdk
2024-12-15 17:31:29,032 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  No Hadoop Dependency available
2024-12-15 17:31:29,032 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JVM Options:
2024-12-15 17:31:29,033 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Xmx469762048
2024-12-15 17:31:29,033 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Xms469762048
2024-12-15 17:31:29,034 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -XX:MaxMetaspaceSize=268435456
2024-12-15 17:31:29,034 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -XX:+IgnoreUnrecognizedVMOptions
2024-12-15 17:31:29,035 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog.file=/opt/flink/log/flink--kubernetes-application-0-stock-pipeline-agg-aapl-59b85f5975-5bzwz.log
2024-12-15 17:31:29,035 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog4j.configuration=file:/opt/flink/conf/log4j-console.properties
2024-12-15 17:31:29,036 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog4j.configurationFile=file:/opt/flink/conf/log4j-console.properties
2024-12-15 17:31:29,036 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlogback.configurationFile=file:/opt/flink/conf/logback-console.xml
2024-12-15 17:31:29,037 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Program Arguments:
2024-12-15 17:31:29,039 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2024-12-15 17:31:29,040 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.off-heap.size=134217728b
2024-12-15 17:31:29,040 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2024-12-15 17:31:29,040 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-overhead.min=201326592b
2024-12-15 17:31:29,041 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2024-12-15 17:31:29,041 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-metaspace.size=268435456b
2024-12-15 17:31:29,041 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2024-12-15 17:31:29,041 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.heap.size=469762048b
2024-12-15 17:31:29,041 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2024-12-15 17:31:29,042 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-overhead.max=201326592b
2024-12-15 17:31:29,042 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Classpath: /opt/flink/lib/flink-cep-1.18.0.jar:/opt/flink/lib/flink-connector-files-1.18.0.jar:/opt/flink/lib/flink-csv-1.18.0.jar:/opt/flink/lib/flink-json-1.18.0.jar:/opt/flink/lib/flink-scala_2.12-1.18.0.jar:/opt/flink/lib/flink-table-api-java-uber-1.18.0.jar:/opt/flink/lib/flink-table-planner-loader-1.18.0.jar:/opt/flink/lib/flink-table-runtime-1.18.0.jar:/opt/flink/lib/log4j-1.2-api-2.17.1.jar:/opt/flink/lib/log4j-api-2.17.1.jar:/opt/flink/lib/log4j-core-2.17.1.jar:/opt/flink/lib/log4j-slf4j-impl-2.17.1.jar:/opt/flink/lib/flink-dist-1.18.0.jar::::
2024-12-15 17:31:29,042 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2024-12-15 17:31:29,045 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Registered UNIX signal handlers for [TERM, HUP, INT]
2024-12-15 17:31:29,128 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: blob.server.port, 6124
2024-12-15 17:31:29,129 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.jobmanager.annotations, flinkdeployment.flink.apache.org/generation:2
2024-12-15 17:31:29,130 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.jobmanager.replicas, 1
2024-12-15 17:31:29,130 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.submit-failed-job-on-application-error, true
2024-12-15 17:31:29,131 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, stock-pipeline-agg-aapl.flink
2024-12-15 17:31:29,131 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.service-account, flink
2024-12-15 17:31:29,132 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.cluster-id, stock-pipeline-agg-aapl
2024-12-15 17:31:29,133 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.taskmanager.cpu.amount, 1.0
2024-12-15 17:31:29,133 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.application.program-args, -pyclientexec;/usr/local/bin/python3;-py;/opt/flink/usrlib/stock_pipeline.py
2024-12-15 17:31:29,134 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 1
2024-12-15 17:31:29,135 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.namespace, flink
2024-12-15 17:31:29,136 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 1
2024-12-15 17:31:29,136 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.rest-service.exposed.type, ClusterIP
2024-12-15 17:31:29,137 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.jobmanager.owner.reference, uid:16fa2cf1-7203-40fd-988a-9e15363a43e5,name:stock-pipeline-agg-aapl,controller:false,blockOwnerDeletion:true,apiVersion:flink.apache.org/v1beta1,kind:FlinkDeployment
2024-12-15 17:31:29,138 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.container.image.ref, nemesysdata/stock-pipeline:latest
2024-12-15 17:31:29,138 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.application.main, org.apache.flink.client.python.PythonDriver
2024-12-15 17:31:29,139 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 1 gb
2024-12-15 17:31:29,140 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.internal.jobmanager.entrypoint.class, org.apache.flink.kubernetes.entrypoint.KubernetesApplicationClusterEntrypoint
2024-12-15 17:31:29,140 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: pipeline.name, stock-pipeline-agg-aapl
2024-12-15 17:31:29,141 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.pod-template-file.taskmanager, /tmp/flink_op_generated_podTemplate_5186896621385261630.yaml
2024-12-15 17:31:29,141 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: web.cancel.enable, false
2024-12-15 17:31:29,142 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.target, kubernetes-application
2024-12-15 17:31:29,142 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1 gb
2024-12-15 17:31:29,143 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.shutdown-on-application-finish, false
2024-12-15 17:31:29,144 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.rpc.port, 6122
2024-12-15 17:31:29,144 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.container.image.pull-policy, Always
2024-12-15 17:31:29,144 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.jobmanager.cpu.amount, 1.0
2024-12-15 17:31:29,145 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: internal.cluster.execution-mode, NORMAL
2024-12-15 17:31:29,145 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.pipeline.job-id, fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:31:29,145 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: pipeline.jars, local:///opt/flink/opt/flink-python_2.12-1.16.1.jar
2024-12-15 17:31:29,146 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.checkpointing.externalized-checkpoint-retention, RETAIN_ON_CANCELLATION
2024-12-15 17:31:29,146 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.flink.version, v1_17
2024-12-15 17:31:29,146 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.pod-template-file.jobmanager, /tmp/flink_op_generated_podTemplate_12708019663807171900.yaml
2024-12-15 17:31:29,147 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.off-heap.size, 134217728b
2024-12-15 17:31:29,147 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.jvm-overhead.min, 201326592b
2024-12-15 17:31:29,147 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.jvm-metaspace.size, 268435456b
2024-12-15 17:31:29,148 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.heap.size, 469762048b
2024-12-15 17:31:29,148 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.jvm-overhead.max, 201326592b
2024-12-15 17:31:30,297 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Starting KubernetesApplicationClusterEntrypoint.
2024-12-15 17:31:30,434 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Install default filesystem.
2024-12-15 17:31:30,444 INFO  org.apache.flink.core.fs.FileSystem                          [] - Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.
2024-12-15 17:31:30,504 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-influx
2024-12-15 17:31:30,535 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-jmx
2024-12-15 17:31:30,536 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-slf4j
2024-12-15 17:31:30,537 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-prometheus
2024-12-15 17:31:30,537 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-datadog
2024-12-15 17:31:30,538 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-statsd
2024-12-15 17:31:30,539 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-graphite
2024-12-15 17:31:30,539 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: external-resource-gpu
2024-12-15 17:31:30,591 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Install security context.
2024-12-15 17:31:30,635 INFO  org.apache.flink.runtime.security.modules.HadoopModuleFactory [] - Cannot create Hadoop Security Module because Hadoop cannot be found in the Classpath.
2024-12-15 17:31:30,646 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /tmp/jaas-15378205903641058399.conf.
2024-12-15 17:31:30,732 INFO  org.apache.flink.runtime.security.contexts.HadoopSecurityContextFactory [] - Cannot install HadoopSecurityContext because Hadoop cannot be found in the Classpath.
2024-12-15 17:31:30,739 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Initializing cluster services.
2024-12-15 17:31:30,798 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Using working directory: WorkingDirectory(/tmp/jm_42c07ba3082982da8b97515e4ba916ca).
2024-12-15 17:31:31,932 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Trying to start actor system, external address stock-pipeline-agg-aapl.flink:6123, bind address 0.0.0.0:6123.
2024-12-15 17:31:34,741 INFO  org.apache.pekko.event.slf4j.Slf4jLogger                     [] - Slf4jLogger started
2024-12-15 17:31:34,991 INFO  org.apache.pekko.remote.RemoteActorRefProvider               [] - Pekko Cluster not in use - enabling unsafe features anyway because `pekko.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2024-12-15 17:31:34,993 INFO  org.apache.pekko.remote.Remoting                             [] - Starting remoting
2024-12-15 17:31:35,731 INFO  org.apache.pekko.remote.Remoting                             [] - Remoting started; listening on addresses :[pekko.tcp://flink@stock-pipeline-agg-aapl.flink:6123]
2024-12-15 17:31:36,537 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Actor system started at pekko.tcp://flink@stock-pipeline-agg-aapl.flink:6123
2024-12-15 17:31:36,635 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Loading delegation token providers
2024-12-15 17:31:36,648 INFO  org.apache.flink.runtime.security.token.hadoop.HadoopFSDelegationTokenProvider [] - Hadoop FS is not available (not packaged with this application): NoClassDefFoundError : "org/apache/hadoop/conf/Configuration".
2024-12-15 17:31:36,648 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token provider hadoopfs loaded and initialized
2024-12-15 17:31:36,653 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token provider hbase loaded and initialized
2024-12-15 17:31:36,654 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2024-12-15 17:31:36,655 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2024-12-15 17:31:36,655 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2024-12-15 17:31:36,655 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2024-12-15 17:31:36,656 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2024-12-15 17:31:36,656 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2024-12-15 17:31:36,657 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2024-12-15 17:31:36,657 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2024-12-15 17:31:36,659 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token providers loaded successfully
2024-12-15 17:31:36,662 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Loading delegation token receivers
2024-12-15 17:31:36,691 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hadoopfs loaded and initialized
2024-12-15 17:31:36,693 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hbase loaded and initialized
2024-12-15 17:31:36,693 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2024-12-15 17:31:36,693 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2024-12-15 17:31:36,694 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2024-12-15 17:31:36,694 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2024-12-15 17:31:36,694 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2024-12-15 17:31:36,694 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2024-12-15 17:31:36,695 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2024-12-15 17:31:36,695 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2024-12-15 17:31:36,696 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receivers loaded successfully
2024-12-15 17:31:36,696 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Checking provider and receiver instances consistency
2024-12-15 17:31:36,696 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Provider and receiver instances are consistent
2024-12-15 17:31:36,697 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Obtaining delegation tokens
2024-12-15 17:31:36,701 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation tokens obtained successfully
2024-12-15 17:31:36,701 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - No tokens obtained so skipping notifications
2024-12-15 17:31:36,744 INFO  org.apache.flink.configuration.Configuration                 [] - Config uses fallback configuration key 'jobmanager.rpc.address' instead of key 'rest.address'
2024-12-15 17:31:36,760 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Created BLOB server storage directory /tmp/jm_42c07ba3082982da8b97515e4ba916ca/blobStorage
2024-12-15 17:31:36,769 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Started BLOB server at 0.0.0.0:6124 - max concurrent requests: 50 - max backlog: 1000
2024-12-15 17:31:36,842 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
2024-12-15 17:31:36,850 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Trying to start actor system, external address stock-pipeline-agg-aapl.flink:0, bind address 0.0.0.0:0.
2024-12-15 17:31:36,993 INFO  org.apache.pekko.event.slf4j.Slf4jLogger                     [] - Slf4jLogger started
2024-12-15 17:31:37,001 INFO  org.apache.pekko.remote.RemoteActorRefProvider               [] - Pekko Cluster not in use - enabling unsafe features anyway because `pekko.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2024-12-15 17:31:37,002 INFO  org.apache.pekko.remote.Remoting                             [] - Starting remoting
2024-12-15 17:31:37,099 INFO  org.apache.pekko.remote.Remoting                             [] - Remoting started; listening on addresses :[pekko.tcp://flink-metrics@stock-pipeline-agg-aapl.flink:39491]
2024-12-15 17:31:37,196 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils      [] - Actor system started at pekko.tcp://flink-metrics@stock-pipeline-agg-aapl.flink:39491
2024-12-15 17:31:37,301 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at pekko://flink-metrics/user/rpc/MetricQueryService .
2024-12-15 17:31:37,962 INFO  org.apache.flink.configuration.Configuration                 [] - Config uses fallback configuration key 'jobmanager.rpc.address' instead of key 'rest.address'
2024-12-15 17:31:38,034 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Upload directory /tmp/flink-web-63f5b663-b5a9-4b2e-abfa-e43db5ba63f5/flink-web-upload does not exist. 
2024-12-15 17:31:38,036 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Created directory /tmp/flink-web-63f5b663-b5a9-4b2e-abfa-e43db5ba63f5/flink-web-upload for file uploads.
2024-12-15 17:31:38,042 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Starting rest endpoint.
2024-12-15 17:31:38,928 INFO  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Determined location of main cluster component log file: /opt/flink/log/flink--kubernetes-application-0-stock-pipeline-agg-aapl-59b85f5975-5bzwz.log
2024-12-15 17:31:38,929 INFO  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Determined location of main cluster component stdout file: /opt/flink/log/flink--kubernetes-application-0-stock-pipeline-agg-aapl-59b85f5975-5bzwz.out
2024-12-15 17:31:39,699 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Rest endpoint listening at stock-pipeline-agg-aapl.flink:8081
2024-12-15 17:31:39,704 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - http://stock-pipeline-agg-aapl.flink:8081 was granted leadership with leaderSessionID=00000000-0000-0000-0000-000000000000
2024-12-15 17:31:39,730 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Web frontend listening at http://stock-pipeline-agg-aapl.flink:8081.
2024-12-15 17:31:39,801 INFO  org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils [] - The derived from fraction jvm overhead memory (102.400mb (107374184 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead
2024-12-15 17:31:39,830 INFO  org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils [] - The derived from fraction network memory (57.600mb (60397978 bytes)) is less than its min value 64.000mb (67108864 bytes), min value will be used instead
2024-12-15 17:31:39,942 WARN  org.apache.flink.kubernetes.entrypoint.KubernetesResourceManagerFactory [] - Configured size for 'taskmanager.memory.process.size' is ignored. Total memory size for TaskManagers are dynamically decided in fine-grained resource management.
2024-12-15 17:31:40,001 INFO  org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner [] - DefaultDispatcherRunner was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new DispatcherLeaderProcess.
2024-12-15 17:31:40,048 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Start SessionDispatcherLeaderProcess.
2024-12-15 17:31:40,098 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl [] - Starting resource manager service.
2024-12-15 17:31:40,137 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl [] - Resource manager service is granted leadership with session id 00000000-0000-0000-0000-000000000000.
2024-12-15 17:31:40,141 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Recover all persisted job graphs that are not finished, yet.
2024-12-15 17:31:40,143 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Successfully recovered 0 persisted job graphs.
2024-12-15 17:31:40,537 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at pekko://flink/user/rpc/dispatcher_0 .
2024-12-15 17:31:41,146 INFO  org.apache.flink.client.ClientUtils                          [] - Starting program (detached: true)
2024-12-15 17:31:42,296 INFO  org.apache.flink.client.python.PythonEnvUtils                [] - Starting Python process with environment variables: {PATH=/opt/flink/bin:/opt/java/openjdk/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin, STOCK_PIPELINE_INGESTION_REST_PORT=tcp://10.39.145.39:8081, FLINK_OPERATOR_WEBHOOK_SERVICE_PORT=tcp://10.32.170.5:443, FLINK_PLUGINS_DIR=/opt/flink/plugins, GPG_KEY=96AE0E32CBE6E0753CE6DF6CB078D1D3253A8D82, STOCK_PIPELINE_AGG_AAPL_REST_PORT=tcp://10.37.184.38:8081, FLINK_CONF_DIR=/opt/flink/conf, FLINK_ENV_JAVA_OPTS=-XX:+IgnoreUnrecognizedVMOptions, STOCK_PIPELINE_AGG_AAPL_REST_SERVICE_PORT=8081, PWD=/opt/flink, STOCK_PIPELINE_INGESTION_REST_SERVICE_HOST=10.39.145.39, STOCK_PIPELINE_INGESTION_REST_PORT_8081_TCP_PORT=8081, KUBERNETES_PORT_443_TCP=tcp://10.32.0.1:443, LANGUAGE=en_US:en, PYTHONPATH=/tmp/pyflink/309b73cf-079a-4ccf-9e47-4703fa393ffc/245a047c-f3c3-4202-9055-65467ee0c3b9:/opt/flink/opt/python/cloudpickle-2.2.0-src.zip:/opt/flink/opt/python/py4j-0.10.9.7-src.zip:/opt/flink/opt/python/pyflink.zip, STOCK_PIPELINE_AGG_AAPL_REST_PORT_8081_TCP_PORT=8081, STOCK_PIPELINE_AGG_AAPL_REST_PORT_8081_TCP=tcp://10.37.184.38:8081, MAX_LOG_FILE_NUMBER=10, DYNAMIC_PARAMETERS=-D jobmanager.memory.off-heap.size=134217728b -D jobmanager.memory.jvm-overhead.min=201326592b -D jobmanager.memory.jvm-metaspace.size=268435456b -D jobmanager.memory.heap.size=469762048b -D jobmanager.memory.jvm-overhead.max=201326592b, STOCK_PIPELINE_INGESTION_REST_SERVICE_PORT=8081, STOCK_PIPELINE_INGESTION_REST_PORT_8081_TCP_ADDR=10.39.145.39, LC_ALL=en_US.UTF-8, KUBERNETES_SERVICE_PORT_HTTPS=443, SHLVL=0, FLINK_BIN_DIR=/opt/flink/bin, FLINK_OPERATOR_WEBHOOK_SERVICE_SERVICE_HOST=10.32.170.5, FLINK_TGZ_URL=https://www.apache.org/dyn/closer.cgi?action=download&filename=flink/flink-1.18.0/flink-1.18.0-bin-scala_2.12.tgz, FLINK_OPERATOR_WEBHOOK_SERVICE_PORT_443_TCP_PORT=443, KUBERNETES_PORT=tcp://10.32.0.1:443, STOCK_PIPELINE_INGESTION_REST_SERVICE_PORT_REST=8081, JAVA_HOME=/opt/java/openjdk, CHECK_GPG=true, _POD_IP_ADDRESS=100.64.2.165, TOPIC=aapl, STOCK_PIPELINE_INGESTION_REST_PORT_8081_TCP_PROTO=tcp, KUBERNETES_SERVICE_HOST=10.32.0.1, LANG=en_US.UTF-8, FLINK_OPERATOR_WEBHOOK_SERVICE_PORT_443_TCP_PROTO=tcp, FLINK_ASC_URL=https://www.apache.org/dist/flink/flink-1.18.0/flink-1.18.0-bin-scala_2.12.tgz.asc, STOCK_PIPELINE_AGG_AAPL_REST_PORT_8081_TCP_ADDR=10.37.184.38, FLINK_OPERATOR_WEBHOOK_SERVICE_PORT_443_TCP_ADDR=10.32.170.5, FLINK_OPERATOR_WEBHOOK_SERVICE_SERVICE_PORT=443, STOCK_PIPELINE_AGG_AAPL_REST_SERVICE_PORT_REST=8081, JAVA_VERSION=jdk-11.0.21+9, STOCK_PIPELINE_INGESTION_REST_PORT_8081_TCP=tcp://10.39.145.39:8081, FLINK_OPT_DIR=/opt/flink/opt, KUBERNETES_PORT_443_TCP_ADDR=10.32.0.1, STOCK_PIPELINE_AGG_AAPL_REST_PORT_8081_TCP_PROTO=tcp, FLINK_HOME=/opt/flink, STEP=AGGREGATE, KUBERNETES_PORT_443_TCP_PROTO=tcp, FLINK_LIB_DIR=/opt/flink/lib, FLINK_OPERATOR_WEBHOOK_SERVICE_PORT_443_TCP=tcp://10.32.170.5:443, PYFLINK_GATEWAY_PORT=37829, KUBERNETES_SERVICE_PORT=443, FLINK_INHERITED_LOGS=


RESOURCE_PARAMS extraction logs:
jvm_params: -Xmx469762048 -Xms469762048 -XX:MaxMetaspaceSize=268435456
dynamic_configs: -D jobmanager.memory.off-heap.size=134217728b -D jobmanager.memory.jvm-overhead.min=201326592b -D jobmanager.memory.jvm-metaspace.size=268435456b -D jobmanager.memory.heap.size=469762048b -D jobmanager.memory.jvm-overhead.max=201326592b
logs: WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.
INFO  [] - Loading configuration property: blob.server.port, 6124
INFO  [] - Loading configuration property: kubernetes.jobmanager.annotations, flinkdeployment.flink.apache.org/generation:2
INFO  [] - Loading configuration property: kubernetes.jobmanager.replicas, 1
INFO  [] - Loading configuration property: execution.submit-failed-job-on-application-error, true
INFO  [] - Loading configuration property: jobmanager.rpc.address, stock-pipeline-agg-aapl.flink
INFO  [] - Loading configuration property: kubernetes.service-account, flink
INFO  [] - Loading configuration property: kubernetes.cluster-id, stock-pipeline-agg-aapl
INFO  [] - Loading configuration property: kubernetes.taskmanager.cpu.amount, 1.0
INFO  [] - Loading configuration property: $internal.application.program-args, -pyclientexec;/usr/local/bin/python3;-py;/opt/flink/usrlib/stock_pipeline.py
INFO  [] - Loading configuration property: parallelism.default, 1
INFO  [] - Loading configuration property: kubernetes.namespace, flink
INFO  [] - Loading configuration property: taskmanager.numberOfTaskSlots, 1
INFO  [] - Loading configuration property: kubernetes.rest-service.exposed.type, ClusterIP
INFO  [] - Loading configuration property: kubernetes.jobmanager.owner.reference, uid:16fa2cf1-7203-40fd-988a-9e15363a43e5,name:stock-pipeline-agg-aapl,controller:false,blockOwnerDeletion:true,apiVersion:flink.apache.org/v1beta1,kind:FlinkDeployment
INFO  [] - Loading configuration property: kubernetes.container.image.ref, nemesysdata/stock-pipeline:latest
INFO  [] - Loading configuration property: $internal.application.main, org.apache.flink.client.python.PythonDriver
INFO  [] - Loading configuration property: taskmanager.memory.process.size, 1 gb
INFO  [] - Loading configuration property: kubernetes.internal.jobmanager.entrypoint.class, org.apache.flink.kubernetes.entrypoint.KubernetesApplicationClusterEntrypoint
INFO  [] - Loading configuration property: pipeline.name, stock-pipeline-agg-aapl
INFO  [] - Loading configuration property: kubernetes.pod-template-file.taskmanager, /tmp/flink_op_generated_podTemplate_5186896621385261630.yaml
INFO  [] - Loading configuration property: web.cancel.enable, false
INFO  [] - Loading configuration property: execution.target, kubernetes-application
INFO  [] - Loading configuration property: jobmanager.memory.process.size, 1 gb
INFO  [] - Loading configuration property: execution.shutdown-on-application-finish, false
INFO  [] - Loading configuration property: taskmanager.rpc.port, 6122
INFO  [] - Loading configuration property: kubernetes.container.image.pull-policy, Always
INFO  [] - Loading configuration property: kubernetes.jobmanager.cpu.amount, 1.0
INFO  [] - Loading configuration property: internal.cluster.execution-mode, NORMAL
INFO  [] - Loading configuration property: $internal.pipeline.job-id, fae872477441fefbceebfb1ff4ad974a
INFO  [] - Loading configuration property: pipeline.jars, local:///opt/flink/opt/flink-python_2.12-1.16.1.jar
INFO  [] - Loading configuration property: execution.checkpointing.externalized-checkpoint-retention, RETAIN_ON_CANCELLATION
INFO  [] - Loading configuration property: $internal.flink.version, v1_17
INFO  [] - Loading configuration property: kubernetes.pod-template-file.jobmanager, /tmp/flink_op_generated_podTemplate_12708019663807171900.yaml
INFO  [] - The derived from fraction jvm overhead memory (102.400mb (107374184 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead
INFO  [] - Final Master Memory configuration:
INFO  [] -   Total Process Memory: 1024.000mb (1073741824 bytes)
INFO  [] -     Total Flink Memory: 576.000mb (603979776 bytes)
INFO  [] -       JVM Heap:         448.000mb (469762048 bytes)
INFO  [] -       Off-heap:         128.000mb (134217728 bytes)
INFO  [] -     JVM Metaspace:      256.000mb (268435456 bytes)
INFO  [] -     JVM Overhead:       192.000mb (201326592 bytes)
, GOSU_VERSION=1.11, HOSTNAME=stock-pipeline-agg-aapl-59b85f5975-5bzwz, JVM_ARGS= -Xmx469762048 -Xms469762048 -XX:MaxMetaspaceSize=268435456, LD_PRELOAD=:/usr/lib/x86_64-linux-gnu/libjemalloc.so, STOCK_PIPELINE_AGG_AAPL_REST_SERVICE_HOST=10.37.184.38, KUBERNETES_PORT_443_TCP_PORT=443, HOME=/opt/flink}, command: /usr/local/bin/python3 -u /opt/flink/usrlib/stock_pipeline.py
2024-12-15 17:31:42,399 INFO  org.apache.flink.client.python.PythonDriver                  [] - --------------------------- Python Process Started --------------------------
2024-12-15 17:31:44,342 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: blob.server.port, 6124
2024-12-15 17:31:44,343 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.jobmanager.annotations, flinkdeployment.flink.apache.org/generation:2
2024-12-15 17:31:44,343 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.jobmanager.replicas, 1
2024-12-15 17:31:44,344 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.submit-failed-job-on-application-error, true
2024-12-15 17:31:44,344 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, stock-pipeline-agg-aapl.flink
2024-12-15 17:31:44,345 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.service-account, flink
2024-12-15 17:31:44,391 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.cluster-id, stock-pipeline-agg-aapl
2024-12-15 17:31:44,392 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.taskmanager.cpu.amount, 1.0
2024-12-15 17:31:44,393 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.application.program-args, -pyclientexec;/usr/local/bin/python3;-py;/opt/flink/usrlib/stock_pipeline.py
2024-12-15 17:31:44,393 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 1
2024-12-15 17:31:44,394 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.namespace, flink
2024-12-15 17:31:44,395 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 1
2024-12-15 17:31:44,396 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.rest-service.exposed.type, ClusterIP
2024-12-15 17:31:44,397 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.jobmanager.owner.reference, uid:16fa2cf1-7203-40fd-988a-9e15363a43e5,name:stock-pipeline-agg-aapl,controller:false,blockOwnerDeletion:true,apiVersion:flink.apache.org/v1beta1,kind:FlinkDeployment
2024-12-15 17:31:44,397 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.container.image.ref, nemesysdata/stock-pipeline:latest
2024-12-15 17:31:44,398 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.application.main, org.apache.flink.client.python.PythonDriver
2024-12-15 17:31:44,398 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 1 gb
2024-12-15 17:31:44,398 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.internal.jobmanager.entrypoint.class, org.apache.flink.kubernetes.entrypoint.KubernetesApplicationClusterEntrypoint
2024-12-15 17:31:44,399 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: pipeline.name, stock-pipeline-agg-aapl
2024-12-15 17:31:44,428 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.pod-template-file.taskmanager, /tmp/flink_op_generated_podTemplate_5186896621385261630.yaml
2024-12-15 17:31:44,428 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: web.cancel.enable, false
2024-12-15 17:31:44,429 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.target, kubernetes-application
2024-12-15 17:31:44,429 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1 gb
2024-12-15 17:31:44,429 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.shutdown-on-application-finish, false
2024-12-15 17:31:44,430 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.rpc.port, 6122
2024-12-15 17:31:44,430 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.container.image.pull-policy, Always
2024-12-15 17:31:44,431 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.jobmanager.cpu.amount, 1.0
2024-12-15 17:31:44,432 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: internal.cluster.execution-mode, NORMAL
2024-12-15 17:31:44,433 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.pipeline.job-id, fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:31:44,434 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: pipeline.jars, local:///opt/flink/opt/flink-python_2.12-1.16.1.jar
2024-12-15 17:31:44,434 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.checkpointing.externalized-checkpoint-retention, RETAIN_ON_CANCELLATION
2024-12-15 17:31:44,435 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.flink.version, v1_17
2024-12-15 17:31:44,436 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: kubernetes.pod-template-file.jobmanager, /tmp/flink_op_generated_podTemplate_12708019663807171900.yaml
2024-12-15 17:31:44,529 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager at pekko://flink/user/rpc/resourcemanager_1 .
2024-12-15 17:31:44,692 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Starting the resource manager.
2024-12-15 17:31:44,736 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Starting the slot manager.
2024-12-15 17:31:44,738 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Starting tokens update task
2024-12-15 17:31:44,740 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - No tokens obtained so skipping notifications
2024-12-15 17:31:44,740 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Tokens update task not started because either no tokens obtained or none of the tokens specified its renewal date
Adding jars
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.flink.api.python.shaded.py4j.reflection.MethodInvoker (file:/opt/flink/opt/flink-python-1.18.0.jar) to method java.net.URLClassLoader.addURL(java.net.URL)
WARNING: Please consider reporting this to the maintainers of org.apache.flink.api.python.shaded.py4j.reflection.MethodInvoker
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2024-12-15 17:31:53,138 INFO  org.apache.flink.kubernetes.KubernetesResourceManagerDriver  [] - Recovered 0 pods from previous attempts, current attempt id is 1.
2024-12-15 17:31:53,139 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Recovered 0 workers from previous attempt.
2024-12-15 17:31:53,295 WARN  org.apache.flink.runtime.webmonitor.retriever.impl.RpcGatewayRetriever [] - Error while retrieving the leader gateway. Retrying to connect to pekko.tcp://flink@stock-pipeline-agg-aapl.flink:6123/user/rpc/resourcemanager_*.
2024-12-15 17:31:53,340 ERROR org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler [] - Exception occurred in REST handler: Cannot connect to ResourceManager right now. Please try to refresh.
Creating Hive tables
  - stocks
2024-12-15 17:31:58,661 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.ddl.SqlCreateCatalog does not contain a setter for field catalogName
2024-12-15 17:31:58,661 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Class class org.apache.flink.sql.parser.ddl.SqlCreateCatalog cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-12-15 17:31:58,664 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.ddl.SqlCreateView does not contain a setter for field viewName
2024-12-15 17:31:58,664 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Class class org.apache.flink.sql.parser.ddl.SqlCreateView cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-12-15 17:31:58,666 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.ddl.SqlAlterViewRename does not contain a getter for field newViewIdentifier
2024-12-15 17:31:58,666 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.ddl.SqlAlterViewRename does not contain a setter for field newViewIdentifier
2024-12-15 17:31:58,666 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Class class org.apache.flink.sql.parser.ddl.SqlAlterViewRename cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-12-15 17:31:58,668 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.ddl.SqlAlterViewProperties does not contain a setter for field propertyList
2024-12-15 17:31:58,668 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Class class org.apache.flink.sql.parser.ddl.SqlAlterViewProperties cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-12-15 17:31:58,691 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.ddl.SqlAlterViewAs does not contain a setter for field newQuery
2024-12-15 17:31:58,692 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Class class org.apache.flink.sql.parser.ddl.SqlAlterViewAs cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-12-15 17:31:58,694 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.ddl.SqlAddPartitions does not contain a setter for field ifPartitionNotExists
2024-12-15 17:31:58,694 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Class class org.apache.flink.sql.parser.ddl.SqlAddPartitions cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-12-15 17:31:58,695 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.ddl.SqlDropPartitions does not contain a setter for field ifExists
2024-12-15 17:31:58,695 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Class class org.apache.flink.sql.parser.ddl.SqlDropPartitions cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-12-15 17:31:58,697 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.dql.SqlShowPartitions does not contain a getter for field tableIdentifier
2024-12-15 17:31:58,697 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.dql.SqlShowPartitions does not contain a setter for field tableIdentifier
2024-12-15 17:31:58,697 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Class class org.apache.flink.sql.parser.dql.SqlShowPartitions cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-12-15 17:31:58,698 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.dml.SqlTruncateTable does not contain a getter for field tableNameIdentifier
2024-12-15 17:31:58,727 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.dml.SqlTruncateTable does not contain a setter for field tableNameIdentifier
2024-12-15 17:31:58,727 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Class class org.apache.flink.sql.parser.dml.SqlTruncateTable cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-12-15 17:31:58,730 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.dql.SqlShowFunctions does not contain a setter for field requireUser
2024-12-15 17:31:58,731 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Class class org.apache.flink.sql.parser.dql.SqlShowFunctions cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-12-15 17:31:58,733 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.dql.SqlShowProcedures does not contain a getter for field databaseName
2024-12-15 17:31:58,733 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.dql.SqlShowProcedures does not contain a setter for field databaseName
2024-12-15 17:31:58,734 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Class class org.apache.flink.sql.parser.dql.SqlShowProcedures cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-12-15 17:31:58,737 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - class org.apache.flink.sql.parser.ddl.SqlReplaceTableAs does not contain a setter for field tableName
2024-12-15 17:31:58,737 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Class class org.apache.flink.sql.parser.ddl.SqlReplaceTableAs cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
  - breakouts
Creating Kafka tables
  - aapl
  - diario_aapl
  - amzn
  - diario_amzn
  - meta
  - diario_meta
  - msft
  - diario_msft
  - tsla
  - diario_tsla
  - stocks
  - diario_stocks
Inserting data into diario_aapl table from aapl
Inserting data into breakouts table
2024-12-15 17:32:23,839 INFO  org.apache.flink.client.deployment.application.executors.EmbeddedExecutor [] - Job fae872477441fefbceebfb1ff4ad974a is submitted.
2024-12-15 17:32:23,840 INFO  org.apache.flink.client.deployment.application.executors.EmbeddedExecutor [] - Submitting Job with JobId=fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:24,883 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'stock-pipeline-agg-aapl' (fae872477441fefbceebfb1ff4ad974a).
2024-12-15 17:32:24,887 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'stock-pipeline-agg-aapl' (fae872477441fefbceebfb1ff4ad974a).
2024-12-15 17:32:24,917 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner [] - JobMasterServiceLeadershipRunner for job fae872477441fefbceebfb1ff4ad974a was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new JobMasterServiceProcess.
2024-12-15 17:32:24,992 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService           [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_2 .
2024-12-15 17:32:25,005 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'stock-pipeline-agg-aapl' (fae872477441fefbceebfb1ff4ad974a).
2024-12-15 17:32:25,117 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy FixedDelayRestartBackoffTimeStrategy(maxNumberRestartAttempts=2147483647, backoffTimeMS=1000) for stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a).
2024-12-15 17:32:25,233 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 67a7484cd2ea9f0f48b04eb287ea6442 for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:25,263 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a).
2024-12-15 17:32:25,264 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 1 ms.
2024-12-15 17:32:25,811 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 2 new pipelined regions in 2 ms, total 2 pipelined regions currently.
2024-12-15 17:32:25,829 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@8bba568
2024-12-15 17:32:25,829 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2024-12-15 17:32:25,831 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2024-12-15 17:32:25,904 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:25,919 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@25cc30a3 for stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a).
2024-12-15 17:32:25,992 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'stock-pipeline-agg-aapl' (fae872477441fefbceebfb1ff4ad974a) under job master id 00000000000000000000000000000000.
2024-12-15 17:32:25,999 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:26,042 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:26,046 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2024-12-15 17:32:26,047 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state CREATED to RUNNING.
2024-12-15 17:32:26,136 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from CREATED to SCHEDULED.
2024-12-15 17:32:26,138 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_0) switched from CREATED to SCHEDULED.
2024-12-15 17:32:26,236 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:26,238 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:26,245 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_0) switched from CREATED to SCHEDULED.
2024-12-15 17:32:26,294 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_0) switched from CREATED to SCHEDULED.
2024-12-15 17:32:26,295 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_0) switched from CREATED to SCHEDULED.
2024-12-15 17:32:26,298 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager pekko.tcp://flink@stock-pipeline-agg-aapl.flink:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2024-12-15 17:32:26,392 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2024-12-15 17:32:26,401 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Registering job manager 00000000000000000000000000000000@pekko.tcp://flink@stock-pipeline-agg-aapl.flink:6123/user/rpc/jobmanager_2 for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:26,438 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Registered job manager 00000000000000000000000000000000@pekko.tcp://flink@stock-pipeline-agg-aapl.flink:6123/user/rpc/jobmanager_2 for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:26,495 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2024-12-15 17:32:26,502 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:26,633 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	(none)
java.util.concurrent.CompletableFuture@6f3065df[Not completed]
2024-12-15 17:32:26,836 INFO  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger checkpoint for job fae872477441fefbceebfb1ff4ad974a since Checkpoint triggering task Source: aapl[1] (1/1) of job fae872477441fefbceebfb1ff4ad974a is not being executed at the moment. Aborting checkpoint. Failure reason: Not all required tasks are currently running..
2024-12-15 17:32:27,028 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - need request 1 new workers, current worker number 0, declared worker number 1
2024-12-15 17:32:27,029 INFO  org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils [] - The derived from fraction jvm overhead memory (92.444mb (96935027 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead
2024-12-15 17:32:27,031 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requesting new worker with resource spec WorkerResourceSpec {cpuCores=1.0, taskHeapSize=25.600mb (26843542 bytes), taskOffHeapSize=0 bytes, networkMemSize=64.000mb (67108864 bytes), managedMemSize=230.400mb (241591914 bytes), numSlots=1}, current pending count: 1.
2024-12-15 17:32:27,092 INFO  org.apache.flink.client.python.PythonDriver                  [] - Adding jars
Creating Hive tables
  - stocks
  - breakouts
Creating Kafka tables
  - aapl
  - diario_aapl
  - amzn
  - diario_amzn
  - meta
  - diario_meta
  - msft
  - diario_msft
  - tsla
  - diario_tsla
  - stocks
  - diario_stocks
Inserting data into diario_aapl table from aapl
Inserting data into breakouts table
java.util.concurrent.CompletableFuture@6f3065df[Not completed]

2024-12-15 17:32:27,094 INFO  org.apache.flink.client.python.PythonDriver                  [] - --------------------------- Python Process Exited ---------------------------
2024-12-15 17:32:27,099 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2024-12-15 17:32:27,337 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:27,337 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:27,340 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error while loading kafka-version.properties: inStream parameter is null
2024-12-15 17:32:27,343 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:27,343 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:27,343 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283947337
2024-12-15 17:32:27,391 INFO  org.apache.flink.configuration.Configuration                 [] - Config uses fallback configuration key 'kubernetes.service-account' instead of key 'kubernetes.taskmanager.service-account'
2024-12-15 17:32:27,394 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:27,395 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:27,395 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283947338
2024-12-15 17:32:27,395 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:27,429 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:27,494 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:27,699 INFO  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger checkpoint for job fae872477441fefbceebfb1ff4ad974a since Checkpoint triggering task Source: aapl[1] (1/1) of job fae872477441fefbceebfb1ff4ad974a is not being executed at the moment. Aborting checkpoint. Failure reason: Not all required tasks are currently running..
2024-12-15 17:32:27,834 INFO  org.apache.flink.kubernetes.KubernetesResourceManagerDriver  [] - Creating new TaskManager pod with name stock-pipeline-agg-aapl-taskmanager-1-1 and resource <1024,1.0>.
2024-12-15 17:32:28,733 INFO  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger checkpoint for job fae872477441fefbceebfb1ff4ad974a since Checkpoint triggering task Source: aapl[1] (1/1) of job fae872477441fefbceebfb1ff4ad974a is not being executed at the moment. Aborting checkpoint. Failure reason: Not all required tasks are currently running..
2024-12-15 17:32:29,730 INFO  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger checkpoint for job fae872477441fefbceebfb1ff4ad974a since Checkpoint triggering task Source: aapl[1] (1/1) of job fae872477441fefbceebfb1ff4ad974a is not being executed at the moment. Aborting checkpoint. Failure reason: Not all required tasks are currently running..
2024-12-15 17:32:29,839 INFO  org.apache.flink.kubernetes.KubernetesResourceManagerDriver  [] - Pod stock-pipeline-agg-aapl-taskmanager-1-1 is created.
2024-12-15 17:32:30,697 INFO  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger checkpoint for job fae872477441fefbceebfb1ff4ad974a since Checkpoint triggering task Source: aapl[1] (1/1) of job fae872477441fefbceebfb1ff4ad974a is not being executed at the moment. Aborting checkpoint. Failure reason: Not all required tasks are currently running..
2024-12-15 17:32:31,003 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:31,028 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:31,154 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:31,196 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:31,197 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:31,204 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:31,204 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:31,207 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:31,227 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from CANCELING to CANCELED.
2024-12-15 17:32:31,228 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_0.
2024-12-15 17:32:31,229 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#0) of source Source: aapl[1].
2024-12-15 17:32:31,230 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_0) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:31,231 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_0) switched from CANCELING to CANCELED.
2024-12-15 17:32:31,232 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_0.
2024-12-15 17:32:31,232 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_0) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:31,232 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_0) switched from CANCELING to CANCELED.
2024-12-15 17:32:31,233 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_0.
2024-12-15 17:32:31,233 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_0) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:31,233 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_0) switched from CANCELING to CANCELED.
2024-12-15 17:32:31,233 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#0) of source Source: diario_aapl[6].
2024-12-15 17:32:31,234 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_0.
2024-12-15 17:32:31,234 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_0) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:31,234 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_0) switched from CANCELING to CANCELED.
2024-12-15 17:32:31,235 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_0.
2024-12-15 17:32:31,633 INFO  org.apache.flink.kubernetes.KubernetesResourceManagerDriver  [] - Received new TaskManager pod: stock-pipeline-agg-aapl-taskmanager-1-1
2024-12-15 17:32:31,638 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requested worker stock-pipeline-agg-aapl-taskmanager-1-1 with resource spec WorkerResourceSpec {cpuCores=1.0, taskHeapSize=25.600mb (26843542 bytes), taskOffHeapSize=0 bytes, networkMemSize=64.000mb (67108864 bytes), managedMemSize=230.400mb (241591914 bytes), numSlots=1}.
2024-12-15 17:32:32,251 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:32,253 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:32,254 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:32,255 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:32,260 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:32,291 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:32,297 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:32,304 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:32,307 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:32,308 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:32,306 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_1) switched from CREATED to SCHEDULED.
2024-12-15 17:32:32,330 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:32,332 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:32,332 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_1) switched from CREATED to SCHEDULED.
2024-12-15 17:32:32,339 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:32,344 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_1) switched from CREATED to SCHEDULED.
2024-12-15 17:32:32,391 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:32,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_1) switched from CREATED to SCHEDULED.
2024-12-15 17:32:32,391 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:32,393 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:32,394 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:32,394 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:32,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_1) switched from CREATED to SCHEDULED.
2024-12-15 17:32:32,397 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:32,398 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:32,402 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:32,429 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:32,443 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:32,444 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:32,444 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:32,446 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283952444
2024-12-15 17:32:32,491 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:32,492 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	(none)
2024-12-15 17:32:32,499 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:32,499 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:32,499 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:32,500 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283952499
2024-12-15 17:32:32,500 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:32,504 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:32,593 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:32,597 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:32,612 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:32,634 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:32,635 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:32,639 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:32,640 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_1) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:32,640 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:32,641 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_1) switched from CANCELING to CANCELED.
2024-12-15 17:32:32,641 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_1.
2024-12-15 17:32:32,642 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_1) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:32,642 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_1) switched from CANCELING to CANCELED.
2024-12-15 17:32:32,642 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#1) of source Source: aapl[1].
2024-12-15 17:32:32,644 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_1.
2024-12-15 17:32:32,645 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_1) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:32,646 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#1) of source Source: diario_aapl[6].
2024-12-15 17:32:32,648 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_1) switched from CANCELING to CANCELED.
2024-12-15 17:32:32,649 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_1.
2024-12-15 17:32:32,650 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_1) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:32,651 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_1) switched from CANCELING to CANCELED.
2024-12-15 17:32:32,653 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_1.
2024-12-15 17:32:32,653 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_1) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:32,654 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_1) switched from CANCELING to CANCELED.
2024-12-15 17:32:32,654 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_1.
2024-12-15 17:32:33,660 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:33,662 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:33,663 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:33,664 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:33,666 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:33,667 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:33,670 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:33,673 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_2) switched from CREATED to SCHEDULED.
2024-12-15 17:32:33,673 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_2) switched from CREATED to SCHEDULED.
2024-12-15 17:32:33,674 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:33,675 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:33,677 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:33,678 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_2) switched from CREATED to SCHEDULED.
2024-12-15 17:32:33,679 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_2) switched from CREATED to SCHEDULED.
2024-12-15 17:32:33,679 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_2) switched from CREATED to SCHEDULED.
2024-12-15 17:32:33,686 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:33,687 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:33,688 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:33,687 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:33,688 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:33,689 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:33,689 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:33,692 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:33,727 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:33,728 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:33,729 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:33,734 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:33,735 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:33,735 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:33,735 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283953735
2024-12-15 17:32:33,738 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:33,740 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:33,744 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:33,744 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:33,745 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:33,745 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283953744
2024-12-15 17:32:33,746 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:33,747 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	(none)
2024-12-15 17:32:33,750 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:33,769 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:33,830 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:33,846 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:33,852 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:33,853 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:33,856 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:33,858 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#2) of source Source: aapl[1].
2024-12-15 17:32:33,858 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:33,858 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_2) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:33,861 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_2) switched from CANCELING to CANCELED.
2024-12-15 17:32:33,861 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_2.
2024-12-15 17:32:33,861 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_2) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:33,861 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_2) switched from CANCELING to CANCELED.
2024-12-15 17:32:33,861 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_2.
2024-12-15 17:32:33,862 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_2) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:33,862 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_2) switched from CANCELING to CANCELED.
2024-12-15 17:32:33,863 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_2.
2024-12-15 17:32:33,863 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#2) of source Source: diario_aapl[6].
2024-12-15 17:32:33,863 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_2) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:33,863 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_2) switched from CANCELING to CANCELED.
2024-12-15 17:32:33,863 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_2.
2024-12-15 17:32:33,863 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_2) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:33,863 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_2) switched from CANCELING to CANCELED.
2024-12-15 17:32:33,864 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_2.
2024-12-15 17:32:34,870 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:34,872 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:34,872 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:34,873 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:34,875 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:34,875 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:34,880 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:34,881 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:34,881 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_3) switched from CREATED to SCHEDULED.
2024-12-15 17:32:34,882 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_3) switched from CREATED to SCHEDULED.
2024-12-15 17:32:34,886 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:34,889 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_3) switched from CREATED to SCHEDULED.
2024-12-15 17:32:34,890 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_3) switched from CREATED to SCHEDULED.
2024-12-15 17:32:34,890 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_3) switched from CREATED to SCHEDULED.
2024-12-15 17:32:34,891 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:34,891 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:34,892 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:34,892 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:34,895 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:34,895 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:34,895 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:34,896 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:34,896 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:34,898 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:34,899 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:34,903 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:34,931 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:34,931 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:34,931 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:34,932 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283954931
2024-12-15 17:32:34,935 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:34,934 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:34,954 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:34,955 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:34,955 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:34,955 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283954955
2024-12-15 17:32:34,955 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:34,992 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	(none)
2024-12-15 17:32:34,994 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:35,000 INFO  org.apache.flink.runtime.checkpoint.CheckpointFailureManager [] - Failed to trigger checkpoint for job fae872477441fefbceebfb1ff4ad974a since Checkpoint triggering task Source: aapl[1] (1/1) of job fae872477441fefbceebfb1ff4ad974a is not being executed at the moment. Aborting checkpoint. Failure reason: Not all required tasks are currently running..
2024-12-15 17:32:35,028 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:35,040 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:35,042 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:35,044 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:35,044 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:35,047 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:35,047 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:35,049 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_3) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:35,049 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#3) of source Source: aapl[1].
2024-12-15 17:32:35,050 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_3) switched from CANCELING to CANCELED.
2024-12-15 17:32:35,050 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_3.
2024-12-15 17:32:35,050 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_3) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:35,051 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_3) switched from CANCELING to CANCELED.
2024-12-15 17:32:35,051 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_3.
2024-12-15 17:32:35,052 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#3) of source Source: diario_aapl[6].
2024-12-15 17:32:35,054 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_3) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:35,054 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_3) switched from CANCELING to CANCELED.
2024-12-15 17:32:35,054 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_3.
2024-12-15 17:32:35,055 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_3) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:35,055 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_3) switched from CANCELING to CANCELED.
2024-12-15 17:32:35,055 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_3.
2024-12-15 17:32:35,056 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_3) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:35,056 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_3) switched from CANCELING to CANCELED.
2024-12-15 17:32:35,056 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_3.
2024-12-15 17:32:36,059 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:36,060 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:36,060 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:36,060 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:36,062 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:36,063 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:36,065 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:36,067 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_4) switched from CREATED to SCHEDULED.
2024-12-15 17:32:36,068 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_4) switched from CREATED to SCHEDULED.
2024-12-15 17:32:36,069 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:36,069 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:36,070 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:36,072 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:36,073 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:36,075 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:36,075 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_4) switched from CREATED to SCHEDULED.
2024-12-15 17:32:36,079 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_4) switched from CREATED to SCHEDULED.
2024-12-15 17:32:36,079 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_4) switched from CREATED to SCHEDULED.
2024-12-15 17:32:36,078 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:36,080 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:36,080 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:36,080 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:36,080 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:36,082 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:36,083 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:36,084 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:36,087 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:36,087 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:36,087 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:36,087 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283956087
2024-12-15 17:32:36,087 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:36,088 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:36,128 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:36,129 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:36,130 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:36,131 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283956129
2024-12-15 17:32:36,132 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:36,137 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:36,145 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	(none)
2024-12-15 17:32:36,152 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:36,229 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:36,238 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:36,242 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:36,243 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:36,247 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:36,248 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:36,249 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_4) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:36,250 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_4) switched from CANCELING to CANCELED.
2024-12-15 17:32:36,250 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#4) of source Source: aapl[1].
2024-12-15 17:32:36,254 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_4.
2024-12-15 17:32:36,257 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_4) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:36,258 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_4) switched from CANCELING to CANCELED.
2024-12-15 17:32:36,258 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_4.
2024-12-15 17:32:36,260 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#4) of source Source: diario_aapl[6].
2024-12-15 17:32:36,260 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_4) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:36,260 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_4) switched from CANCELING to CANCELED.
2024-12-15 17:32:36,261 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_4.
2024-12-15 17:32:36,261 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_4) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:36,261 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_4) switched from CANCELING to CANCELED.
2024-12-15 17:32:36,261 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_4.
2024-12-15 17:32:36,261 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_4) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:36,261 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_4) switched from CANCELING to CANCELED.
2024-12-15 17:32:36,261 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_4.
2024-12-15 17:32:37,267 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:37,268 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:37,268 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:37,269 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:37,270 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:37,270 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:37,273 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:37,274 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:37,275 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_5) switched from CREATED to SCHEDULED.
2024-12-15 17:32:37,276 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_5) switched from CREATED to SCHEDULED.
2024-12-15 17:32:37,277 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:37,281 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_5) switched from CREATED to SCHEDULED.
2024-12-15 17:32:37,281 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_5) switched from CREATED to SCHEDULED.
2024-12-15 17:32:37,282 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_5) switched from CREATED to SCHEDULED.
2024-12-15 17:32:37,282 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:37,290 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:37,290 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:37,291 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:37,291 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:37,291 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:37,292 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:37,294 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:37,295 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:37,328 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:37,328 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:37,330 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:37,334 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:37,335 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:37,336 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:37,336 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:37,336 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283957336
2024-12-15 17:32:37,340 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:37,347 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:37,348 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:37,348 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:37,349 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283957348
2024-12-15 17:32:37,349 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:37,351 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:37,353 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	(none)
2024-12-15 17:32:37,443 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:37,441 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:37,454 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:37,457 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:37,457 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:37,460 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:37,463 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:37,463 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_5) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:37,464 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_5) switched from CANCELING to CANCELED.
2024-12-15 17:32:37,464 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_5.
2024-12-15 17:32:37,464 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_5) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:37,465 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#5) of source Source: aapl[1].
2024-12-15 17:32:37,491 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_5) switched from CANCELING to CANCELED.
2024-12-15 17:32:37,491 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_5.
2024-12-15 17:32:37,492 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_5) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:37,492 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#5) of source Source: diario_aapl[6].
2024-12-15 17:32:37,493 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_5) switched from CANCELING to CANCELED.
2024-12-15 17:32:37,528 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_5.
2024-12-15 17:32:37,529 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_5) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:37,530 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_5) switched from CANCELING to CANCELED.
2024-12-15 17:32:37,534 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_5.
2024-12-15 17:32:37,535 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_5) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:37,536 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_5) switched from CANCELING to CANCELED.
2024-12-15 17:32:37,539 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_5.
2024-12-15 17:32:38,546 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:38,548 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:38,549 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:38,549 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:38,552 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:38,552 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:38,558 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:38,559 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:38,560 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_6) switched from CREATED to SCHEDULED.
2024-12-15 17:32:38,563 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_6) switched from CREATED to SCHEDULED.
2024-12-15 17:32:38,563 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:38,567 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:38,567 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_6) switched from CREATED to SCHEDULED.
2024-12-15 17:32:38,569 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_6) switched from CREATED to SCHEDULED.
2024-12-15 17:32:38,570 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_6) switched from CREATED to SCHEDULED.
2024-12-15 17:32:38,571 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:38,572 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:38,572 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:38,572 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:38,573 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:38,573 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:38,574 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:38,575 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:38,576 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:38,577 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:38,579 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:38,581 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:38,630 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:38,630 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:38,631 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:38,631 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283958630
2024-12-15 17:32:38,633 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:38,634 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	(none)
2024-12-15 17:32:38,634 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:38,634 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:38,635 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:38,635 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283958633
2024-12-15 17:32:38,635 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:38,642 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:38,663 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:38,691 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:38,739 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:38,745 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:38,745 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:38,752 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:38,753 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:38,754 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_6) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:38,754 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#6) of source Source: aapl[1].
2024-12-15 17:32:38,754 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_6) switched from CANCELING to CANCELED.
2024-12-15 17:32:38,760 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_6.
2024-12-15 17:32:38,760 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_6) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:38,761 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_6) switched from CANCELING to CANCELED.
2024-12-15 17:32:38,762 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_6.
2024-12-15 17:32:38,763 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#6) of source Source: diario_aapl[6].
2024-12-15 17:32:38,764 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_6) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:38,764 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_6) switched from CANCELING to CANCELED.
2024-12-15 17:32:38,764 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_6.
2024-12-15 17:32:38,765 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_6) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:38,765 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_6) switched from CANCELING to CANCELED.
2024-12-15 17:32:38,765 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_6.
2024-12-15 17:32:38,765 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_6) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:38,766 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_6) switched from CANCELING to CANCELED.
2024-12-15 17:32:38,766 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_6.
2024-12-15 17:32:39,768 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:39,769 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:39,770 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:39,770 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:39,771 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:39,772 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:39,774 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:39,778 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:39,779 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:39,780 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_7) switched from CREATED to SCHEDULED.
2024-12-15 17:32:39,780 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_7) switched from CREATED to SCHEDULED.
2024-12-15 17:32:39,781 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:39,782 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:39,783 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:39,784 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:39,785 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:39,784 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:39,794 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:39,788 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_7) switched from CREATED to SCHEDULED.
2024-12-15 17:32:39,795 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_7) switched from CREATED to SCHEDULED.
2024-12-15 17:32:39,795 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_7) switched from CREATED to SCHEDULED.
2024-12-15 17:32:39,796 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:39,797 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:39,799 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:39,802 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:39,802 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:39,802 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:39,802 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:39,802 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:39,803 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283959802
2024-12-15 17:32:39,805 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:39,806 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:39,818 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:39,819 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:39,820 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:39,820 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283959819
2024-12-15 17:32:39,821 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:39,836 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:39,851 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:39,892 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	(none)
2024-12-15 17:32:39,908 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:39,919 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:39,931 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:39,932 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:39,935 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_7) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:39,935 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_7) switched from CANCELING to CANCELED.
2024-12-15 17:32:39,936 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#7) of source Source: aapl[1].
2024-12-15 17:32:39,937 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:39,937 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:39,945 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_7.
2024-12-15 17:32:39,946 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_7) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:39,946 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_7) switched from CANCELING to CANCELED.
2024-12-15 17:32:39,946 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_7.
2024-12-15 17:32:39,947 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#7) of source Source: diario_aapl[6].
2024-12-15 17:32:39,947 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_7) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:39,947 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_7) switched from CANCELING to CANCELED.
2024-12-15 17:32:39,947 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_7.
2024-12-15 17:32:39,948 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_7) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:39,948 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_7) switched from CANCELING to CANCELED.
2024-12-15 17:32:39,948 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_7.
2024-12-15 17:32:39,949 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_7) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:39,949 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_7) switched from CANCELING to CANCELED.
2024-12-15 17:32:39,949 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_7.
2024-12-15 17:32:40,952 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:40,953 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:40,953 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:40,954 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:40,955 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:40,955 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:40,957 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:40,959 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_8) switched from CREATED to SCHEDULED.
2024-12-15 17:32:40,960 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_8) switched from CREATED to SCHEDULED.
2024-12-15 17:32:40,961 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:40,961 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:40,961 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:40,959 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:40,963 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:40,963 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:40,963 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_8) switched from CREATED to SCHEDULED.
2024-12-15 17:32:40,963 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:40,964 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_8) switched from CREATED to SCHEDULED.
2024-12-15 17:32:40,965 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_8) switched from CREATED to SCHEDULED.
2024-12-15 17:32:40,964 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:40,969 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:40,969 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:40,969 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:40,971 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:40,972 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:40,972 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:40,975 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:40,975 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:40,976 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:40,976 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:40,976 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283960975
2024-12-15 17:32:40,977 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:40,980 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:40,980 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:40,980 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:40,980 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283960980
2024-12-15 17:32:40,981 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:40,983 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:41,031 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	(none)
2024-12-15 17:32:41,043 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:41,051 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:41,056 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:41,062 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:41,063 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:41,066 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:41,066 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:41,068 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_8) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:41,068 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_8) switched from CANCELING to CANCELED.
2024-12-15 17:32:41,068 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_8.
2024-12-15 17:32:41,068 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_8) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:41,069 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_8) switched from CANCELING to CANCELED.
2024-12-15 17:32:41,069 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_8.
2024-12-15 17:32:41,069 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#8) of source Source: aapl[1].
2024-12-15 17:32:41,070 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#8) of source Source: diario_aapl[6].
2024-12-15 17:32:41,070 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_8) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:41,071 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_8) switched from CANCELING to CANCELED.
2024-12-15 17:32:41,071 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_8.
2024-12-15 17:32:41,072 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_8) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:41,072 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_8) switched from CANCELING to CANCELED.
2024-12-15 17:32:41,072 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_8.
2024-12-15 17:32:41,073 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_8) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:41,074 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_8) switched from CANCELING to CANCELED.
2024-12-15 17:32:41,074 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_8.
2024-12-15 17:32:42,079 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:42,081 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:42,081 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:42,082 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:42,084 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:42,085 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:42,089 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:42,092 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:42,092 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_9) switched from CREATED to SCHEDULED.
2024-12-15 17:32:42,096 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_9) switched from CREATED to SCHEDULED.
2024-12-15 17:32:42,097 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:42,097 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:42,097 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:42,098 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:42,095 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:42,099 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:42,100 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:42,100 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_9) switched from CREATED to SCHEDULED.
2024-12-15 17:32:42,101 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_9) switched from CREATED to SCHEDULED.
2024-12-15 17:32:42,102 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_9) switched from CREATED to SCHEDULED.
2024-12-15 17:32:42,105 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:42,106 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:42,106 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:42,107 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:42,113 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:42,114 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:42,118 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:42,118 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:42,118 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:42,118 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283962118
2024-12-15 17:32:42,118 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:42,128 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:42,137 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:42,138 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:42,139 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:42,139 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283962137
2024-12-15 17:32:42,139 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:42,191 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:42,191 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	(none)
2024-12-15 17:32:42,203 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:42,214 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:42,221 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:42,224 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:42,225 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:42,228 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#9) of source Source: aapl[1].
2024-12-15 17:32:42,228 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_9) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:42,229 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_9) switched from CANCELING to CANCELED.
2024-12-15 17:32:42,230 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_9.
2024-12-15 17:32:42,227 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:42,231 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:42,231 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_9) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:42,232 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_9) switched from CANCELING to CANCELED.
2024-12-15 17:32:42,232 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_9.
2024-12-15 17:32:42,234 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_9) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:42,235 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_9) switched from CANCELING to CANCELED.
2024-12-15 17:32:42,235 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_9.
2024-12-15 17:32:42,236 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_9) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:42,236 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#9) of source Source: diario_aapl[6].
2024-12-15 17:32:42,237 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_9) switched from CANCELING to CANCELED.
2024-12-15 17:32:42,237 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_9.
2024-12-15 17:32:42,237 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_9) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:42,237 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_9) switched from CANCELING to CANCELED.
2024-12-15 17:32:42,238 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_9.
2024-12-15 17:32:43,243 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:43,245 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:43,245 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:43,245 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:43,247 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:43,247 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:43,252 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_10) switched from CREATED to SCHEDULED.
2024-12-15 17:32:43,252 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_10) switched from CREATED to SCHEDULED.
2024-12-15 17:32:43,252 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:43,251 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:43,259 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:43,260 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:43,262 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:43,262 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:43,262 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:43,264 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:43,265 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:43,265 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_10) switched from CREATED to SCHEDULED.
2024-12-15 17:32:43,265 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_10) switched from CREATED to SCHEDULED.
2024-12-15 17:32:43,265 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_10) switched from CREATED to SCHEDULED.
2024-12-15 17:32:43,266 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:43,267 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:43,267 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:43,268 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:43,272 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:43,273 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:43,327 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:43,328 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	(none)
2024-12-15 17:32:43,331 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:43,331 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:43,332 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:43,332 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283963331
2024-12-15 17:32:43,335 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:43,339 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:43,340 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:43,342 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:43,342 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283963340
2024-12-15 17:32:43,343 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:43,346 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:43,361 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:43,365 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:43,370 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:43,372 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:43,372 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:43,392 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:43,392 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:43,430 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#10) of source Source: aapl[1].
2024-12-15 17:32:43,431 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_10) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:43,432 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_10) switched from CANCELING to CANCELED.
2024-12-15 17:32:43,433 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_10.
2024-12-15 17:32:43,433 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_10) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:43,434 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_10) switched from CANCELING to CANCELED.
2024-12-15 17:32:43,435 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_10.
2024-12-15 17:32:43,436 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_10) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:43,436 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#10) of source Source: diario_aapl[6].
2024-12-15 17:32:43,437 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_10) switched from CANCELING to CANCELED.
2024-12-15 17:32:43,437 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_10.
2024-12-15 17:32:43,438 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_10) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:43,438 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_10) switched from CANCELING to CANCELED.
2024-12-15 17:32:43,438 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_10.
2024-12-15 17:32:43,438 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_10) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:43,439 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_10) switched from CANCELING to CANCELED.
2024-12-15 17:32:43,439 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_10.
2024-12-15 17:32:44,444 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:44,445 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:44,446 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:44,446 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:44,448 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:44,447 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:44,449 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:44,450 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_11) switched from CREATED to SCHEDULED.
2024-12-15 17:32:44,450 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:44,451 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_11) switched from CREATED to SCHEDULED.
2024-12-15 17:32:44,453 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_11) switched from CREATED to SCHEDULED.
2024-12-15 17:32:44,454 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_11) switched from CREATED to SCHEDULED.
2024-12-15 17:32:44,454 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_11) switched from CREATED to SCHEDULED.
2024-12-15 17:32:44,455 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:44,455 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:44,462 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:44,462 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:44,463 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:44,463 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:44,464 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:44,464 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:44,466 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:44,467 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:44,467 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:44,468 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:44,471 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:44,472 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:44,477 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:44,477 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:44,478 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:44,479 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283964477
2024-12-15 17:32:44,529 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:44,529 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:44,533 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	(none)
2024-12-15 17:32:44,538 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:44,538 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:44,538 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283964538
2024-12-15 17:32:44,538 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:44,540 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:44,559 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:44,565 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:44,567 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:44,567 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:44,569 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:44,570 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:44,570 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:44,571 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_11) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:44,571 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#11) of source Source: aapl[1].
2024-12-15 17:32:44,572 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_11) switched from CANCELING to CANCELED.
2024-12-15 17:32:44,573 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_11.
2024-12-15 17:32:44,574 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_11) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:44,574 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_11) switched from CANCELING to CANCELED.
2024-12-15 17:32:44,574 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_11.
2024-12-15 17:32:44,575 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_11) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:44,575 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#11) of source Source: diario_aapl[6].
2024-12-15 17:32:44,575 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_11) switched from CANCELING to CANCELED.
2024-12-15 17:32:44,576 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_11.
2024-12-15 17:32:44,576 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_11) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:44,576 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_11) switched from CANCELING to CANCELED.
2024-12-15 17:32:44,576 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_11.
2024-12-15 17:32:44,577 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_11) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:44,577 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_11) switched from CANCELING to CANCELED.
2024-12-15 17:32:44,577 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_11.
2024-12-15 17:32:45,579 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:45,580 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:45,580 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:45,580 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:45,581 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:45,582 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:45,583 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:45,585 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_12) switched from CREATED to SCHEDULED.
2024-12-15 17:32:45,585 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_12) switched from CREATED to SCHEDULED.
2024-12-15 17:32:45,587 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:45,587 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:45,587 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:45,587 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:45,589 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:45,587 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_12) switched from CREATED to SCHEDULED.
2024-12-15 17:32:45,590 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_12) switched from CREATED to SCHEDULED.
2024-12-15 17:32:45,590 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_12) switched from CREATED to SCHEDULED.
2024-12-15 17:32:45,590 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:45,591 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:45,589 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:45,594 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:45,594 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:45,594 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:45,594 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:45,596 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:45,596 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:45,599 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:45,600 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:45,600 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:45,601 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:45,601 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283965600
2024-12-15 17:32:45,603 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:45,608 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:45,609 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:45,609 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:45,609 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283965609
2024-12-15 17:32:45,609 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:45,615 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:45,640 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:45,691 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	(none)
2024-12-15 17:32:45,697 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:45,703 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:45,708 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:45,710 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:45,715 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_12) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:45,716 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:45,716 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:45,716 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_12) switched from CANCELING to CANCELED.
2024-12-15 17:32:45,716 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#12) of source Source: aapl[1].
2024-12-15 17:32:45,718 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_12.
2024-12-15 17:32:45,719 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_12) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:45,719 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_12) switched from CANCELING to CANCELED.
2024-12-15 17:32:45,720 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_12.
2024-12-15 17:32:45,729 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#12) of source Source: diario_aapl[6].
2024-12-15 17:32:45,729 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_12) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:45,730 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_12) switched from CANCELING to CANCELED.
2024-12-15 17:32:45,733 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_12.
2024-12-15 17:32:45,733 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_12) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:45,733 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_12) switched from CANCELING to CANCELED.
2024-12-15 17:32:45,733 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_12.
2024-12-15 17:32:45,734 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_12) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:45,734 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_12) switched from CANCELING to CANCELED.
2024-12-15 17:32:45,734 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_12.
2024-12-15 17:32:46,738 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:46,739 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:46,739 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:46,739 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:46,743 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:46,743 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:46,746 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:46,748 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_13) switched from CREATED to SCHEDULED.
2024-12-15 17:32:46,748 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_13) switched from CREATED to SCHEDULED.
2024-12-15 17:32:46,748 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:46,749 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:46,752 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:46,755 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_13) switched from CREATED to SCHEDULED.
2024-12-15 17:32:46,752 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:46,756 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_13) switched from CREATED to SCHEDULED.
2024-12-15 17:32:46,757 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_13) switched from CREATED to SCHEDULED.
2024-12-15 17:32:46,755 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:46,756 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:46,759 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:46,760 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:46,760 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:46,791 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:46,791 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:46,792 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:46,793 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:46,796 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:46,796 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:46,830 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	(none)
2024-12-15 17:32:46,831 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:46,834 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:46,834 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:46,835 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283966834
2024-12-15 17:32:46,833 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:46,837 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:46,837 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:46,837 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283966836
2024-12-15 17:32:46,837 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:46,838 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:46,841 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:46,932 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:46,941 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:46,940 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:46,943 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:46,943 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:46,948 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_13) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:46,949 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_13) switched from CANCELING to CANCELED.
2024-12-15 17:32:46,949 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_13.
2024-12-15 17:32:46,950 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_13) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:46,950 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_13) switched from CANCELING to CANCELED.
2024-12-15 17:32:46,950 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_13.
2024-12-15 17:32:46,952 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_13) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:46,991 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#13) of source Source: diario_aapl[6].
2024-12-15 17:32:46,952 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_13) switched from CANCELING to CANCELED.
2024-12-15 17:32:46,991 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:46,991 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#13) of source Source: aapl[1].
2024-12-15 17:32:46,992 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:46,993 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_13.
2024-12-15 17:32:46,994 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_13) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:46,994 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_13) switched from CANCELING to CANCELED.
2024-12-15 17:32:46,994 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_13.
2024-12-15 17:32:46,995 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_13) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:46,995 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_13) switched from CANCELING to CANCELED.
2024-12-15 17:32:46,997 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_13.
2024-12-15 17:32:47,896 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Registering TaskManager with ResourceID stock-pipeline-agg-aapl-taskmanager-1-1 (pekko.tcp://flink@100.64.2.154:6122/user/rpc/taskmanager_0) at ResourceManager
2024-12-15 17:32:48,000 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:48,007 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:48,007 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:48,007 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:48,009 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:48,009 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:48,011 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_14) switched from CREATED to SCHEDULED.
2024-12-15 17:32:48,011 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:48,013 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_14) switched from CREATED to SCHEDULED.
2024-12-15 17:32:48,013 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:48,015 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:48,018 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:48,018 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:48,018 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:48,020 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:48,023 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:48,027 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:48,024 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:48,024 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_14) switched from CREATED to SCHEDULED.
2024-12-15 17:32:48,030 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_14) switched from CREATED to SCHEDULED.
2024-12-15 17:32:48,029 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:48,030 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:48,031 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_14) switched from CREATED to SCHEDULED.
2024-12-15 17:32:48,032 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:48,038 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:48,038 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:48,038 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:48,038 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283968038
2024-12-15 17:32:48,039 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:48,040 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:48,044 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:48,045 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:48,045 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Registering task executor stock-pipeline-agg-aapl-taskmanager-1-1 under c75f96f6dd50c8ad9e1be87dbcdca3de at the slot manager.
2024-12-15 17:32:48,052 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Worker stock-pipeline-agg-aapl-taskmanager-1-1 is registered.
2024-12-15 17:32:48,053 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:48,053 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:48,053 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:48,053 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283968053
2024-12-15 17:32:48,053 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:48,056 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:48,057 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Worker stock-pipeline-agg-aapl-taskmanager-1-1 with resource spec WorkerResourceSpec {cpuCores=1.0, taskHeapSize=25.600mb (26843542 bytes), taskOffHeapSize=0 bytes, networkMemSize=64.000mb (67108864 bytes), managedMemSize=230.400mb (241591914 bytes), numSlots=1} was requested in current attempt. Current pending count after registering: 0.
2024-12-15 17:32:48,098 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Matching resource requirements against available resources.
Missing resources:
	 Job fae872477441fefbceebfb1ff4ad974a
		ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}
Current resources:
	TaskManager stock-pipeline-agg-aapl-taskmanager-1-1
		Available: ResourceProfile{cpuCores=1, taskHeapMemory=25.600mb (26843542 bytes), taskOffHeapMemory=0 bytes, managedMemory=230.400mb (241591914 bytes), networkMemory=64.000mb (67108864 bytes)}
		Total:     ResourceProfile{cpuCores=1, taskHeapMemory=25.600mb (26843542 bytes), taskOffHeapMemory=0 bytes, managedMemory=230.400mb (241591914 bytes), networkMemory=64.000mb (67108864 bytes)}
2024-12-15 17:32:48,102 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer [] - Starting allocation of slot 565083ddc18dbe0ebd124a65c16222a8 from stock-pipeline-agg-aapl-taskmanager-1-1 for job fae872477441fefbceebfb1ff4ad974a with resource profile ResourceProfile{cpuCores=1, taskHeapMemory=25.600mb (26843542 bytes), taskOffHeapMemory=0 bytes, managedMemory=230.400mb (241591914 bytes), networkMemory=64.000mb (67108864 bytes)}.
2024-12-15 17:32:48,129 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:48,136 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:48,138 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
2024-12-15 17:32:48,138 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RUNNING to RESTARTING.
2024-12-15 17:32:48,142 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_14) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:48,142 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#14) of source Source: aapl[1].
2024-12-15 17:32:48,142 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_14) switched from CANCELING to CANCELED.
2024-12-15 17:32:48,142 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_14.
2024-12-15 17:32:48,143 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_14) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:48,143 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_14) switched from CANCELING to CANCELED.
2024-12-15 17:32:48,143 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_14.
2024-12-15 17:32:48,147 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_14) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:48,147 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_14) switched from CANCELING to CANCELED.
2024-12-15 17:32:48,147 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_14.
2024-12-15 17:32:48,147 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_14) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:48,147 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_14) switched from CANCELING to CANCELED.
2024-12-15 17:32:48,147 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_14.
2024-12-15 17:32:48,147 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_14) switched from SCHEDULED to CANCELING.
2024-12-15 17:32:48,147 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_14) switched from CANCELING to CANCELED.
2024-12-15 17:32:48,147 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_14.
2024-12-15 17:32:48,191 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Removing registered reader after failure for subtask 0 (#14) of source Source: diario_aapl[6].
2024-12-15 17:32:48,191 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:48,194 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Clearing resource requirements of job fae872477441fefbceebfb1ff4ad974a
2024-12-15 17:32:48,194 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedTaskManagerTracker [] - Clear all pending allocations for job fae872477441fefbceebfb1ff4ad974a.
2024-12-15 17:32:49,151 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job stock-pipeline-agg-aapl (fae872477441fefbceebfb1ff4ad974a) switched from state RESTARTING to RUNNING.
2024-12-15 17:32:49,152 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-12-15 17:32:49,153 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Resetting the Operator Coordinators to an empty state.
2024-12-15 17:32:49,153 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:49,154 INFO  org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator [] - Resetting coordinator to checkpoint.
2024-12-15 17:32:49,154 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: aapl[1].
2024-12-15 17:32:49,156 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:49,157 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_15) switched from CREATED to SCHEDULED.
2024-12-15 17:32:49,157 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_15) switched from CREATED to SCHEDULED.
2024-12-15 17:32:49,157 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: diario_aapl[6].
2024-12-15 17:32:49,158 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:49,160 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:49,160 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:49,160 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - App info kafka.admin.client for StockPipeline_aapl-enumerator-admin-client unregistered
2024-12-15 17:32:49,162 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager [] - Received resource requirements from job fae872477441fefbceebfb1ff4ad974a: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-12-15 17:32:49,162 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: aapl[1] closed.
2024-12-15 17:32:49,163 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: aapl[1].
2024-12-15 17:32:49,166 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics scheduler closed
2024-12-15 17:32:49,166 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter
2024-12-15 17:32:49,166 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:49,167 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics [] - Metrics reporters closed
2024-12-15 17:32:49,175 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: diario_aapl[6] closed.
2024-12-15 17:32:49,175 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: diario_aapl[6].
2024-12-15 17:32:49,176 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:49,177 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:49,177 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:49,177 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283969177
2024-12-15 17:32:49,178 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: aapl[1] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_15) switched from SCHEDULED to DEPLOYING.
2024-12-15 17:32:49,180 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:49,229 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: aapl[1] (1/1) (attempt #15) with attempt id 67a7484cd2ea9f0f48b04eb287ea6442_bc764cd8ddf7a0cff126f51c16239658_0_15 and vertex id bc764cd8ddf7a0cff126f51c16239658_0 to stock-pipeline-agg-aapl-taskmanager-1-1 @ 100.64.2.154 (dataPort=36735) with allocation id 565083ddc18dbe0ebd124a65c16222a8
2024-12-15 17:32:49,229 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [demo-kafka-kafka-plain-bootstrap.kafka.svc:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = StockPipeline_aapl-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-15 17:32:49,238 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig [] - These configurations '[key.deserializer, value.deserializer, enable.auto.commit, client.id.prefix, group.id, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.
2024-12-15 17:32:49,239 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka version: unknown
2024-12-15 17:32:49,239 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka commitId: unknown
2024-12-15 17:32:49,239 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Kafka startTimeMs: 1734283969239
2024-12-15 17:32:49,239 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser [] - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=StockPipeline_aapl-enumerator-admin-client
	at com.sun.jmx.mbeanserver.Repository.addMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(Unknown Source) ~[?:?]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(Unknown Source) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:602) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:544) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:488) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.Admin.create(Admin.java:134) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:441) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:164) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:233) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:469) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
2024-12-15 17:32:49,241 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group StockPipeline_aapl with partition discovery interval of 300000 ms.
2024-12-15 17:32:49,250 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [AAPL-0]
2024-12-15 17:32:49,256 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_15) switched from SCHEDULED to DEPLOYING.
2024-12-15 17:32:49,262 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying GroupWindowAggregate[3] -> Calc[4] -> diario_aapl[5]: Writer -> diario_aapl[5]: Committer (1/1) (attempt #15) with attempt id 67a7484cd2ea9f0f48b04eb287ea6442_51397532e2d9c7a21097a30d590b3114_0_15 and vertex id 51397532e2d9c7a21097a30d590b3114_0 to stock-pipeline-agg-aapl-taskmanager-1-1 @ 100.64.2.154 (dataPort=36735) with allocation id 565083ddc18dbe0ebd124a65c16222a8
2024-12-15 17:32:49,331 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: diario_aapl[6]. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]
	at java.lang.Thread.run(Unknown Source) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[blob_p-8c674039fa373bc13483226f93eeecc46472e56a-944591252d2bcc00505f82800a7574a9:3.1.0-1.18]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:49,347 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_15) switched from CREATED to SCHEDULED.
2024-12-15 17:32:49,348 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_15) switched from CREATED to SCHEDULED.
2024-12-15 17:32:49,349 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_15) switched from CREATED to SCHEDULED.
2024-12-15 17:32:49,350 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: diario_aapl[6] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_15) switched from SCHEDULED to DEPLOYING.
2024-12-15 17:32:49,350 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: diario_aapl[6] (1/1) (attempt #15) with attempt id 67a7484cd2ea9f0f48b04eb287ea6442_feca28aff5a3958840bee985ee7de4d3_0_15 and vertex id feca28aff5a3958840bee985ee7de4d3_0 to stock-pipeline-agg-aapl-taskmanager-1-1 @ 100.64.2.154 (dataPort=36735) with allocation id 565083ddc18dbe0ebd124a65c16222a8
2024-12-15 17:32:49,352 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[8] -> Calc[9] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_15) switched from SCHEDULED to DEPLOYING.
2024-12-15 17:32:49,352 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying OverAggregate[8] -> Calc[9] (1/1) (attempt #15) with attempt id 67a7484cd2ea9f0f48b04eb287ea6442_8b9f3e513101bcc5d198aee685286d98_0_15 and vertex id 8b9f3e513101bcc5d198aee685286d98_0 to stock-pipeline-agg-aapl-taskmanager-1-1 @ 100.64.2.154 (dataPort=36735) with allocation id 565083ddc18dbe0ebd124a65c16222a8
2024-12-15 17:32:49,357 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_15) switched from SCHEDULED to DEPLOYING.
2024-12-15 17:32:49,358 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying OverAggregate[11] -> Calc[12] -> ConstraintEnforcer[13] -> Sink: breakouts[13] (1/1) (attempt #15) with attempt id 67a7484cd2ea9f0f48b04eb287ea6442_85b8bf226eae7a4cd07fec1c0cbb4b9c_0_15 and vertex id 85b8bf226eae7a4cd07fec1c0cbb4b9c_0 to stock-pipeline-agg-aapl-taskmanager-1-1 @ 100.64.2.154 (dataPort=36735) with allocation id 565083ddc18dbe0ebd124a65c16222a8
2024-12-15 17:32:49,371 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: diario_aapl[6]' (operator feca28aff5a3958840bee985ee7de4d3).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:624) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:248) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:395) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:408) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) ~[?:?]
	at java.lang.Thread.run(Unknown Source) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:248) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$4(ExecutorNotifier.java:133) ~[flink-dist-1.18.0.jar:1.18.0]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[flink-dist-1.18.0.jar:1.18.0]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [DIARIO_AAPL].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(Unknown Source) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(Unknown Source) ~[?:?]
	at org.apache.flink.kafka.shaded.org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[?:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:233) ~[?:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$5(ExecutorNotifier.java:130) ~[flink-dist-1.18.0.jar:1.18.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[?:?]
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source) ~[?:?]
	... 4 more
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2024-12-15 17:32:49,379 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - 5 tasks will be restarted to recover from a global failure.
